{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5de2004a-5231-4a73-8121-4829b7cb7d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: requests\n",
      "Version: 2.32.3\n",
      "Summary: Python HTTP for Humans.\n",
      "Home-page: https://requests.readthedocs.io\n",
      "Author: Kenneth Reitz\n",
      "Author-email: me@kennethreitz.org\n",
      "License: Apache-2.0\n",
      "Location: C:\\Users\\hun\\anaconda3\\Lib\\site-packages\n",
      "Requires: certifi, charset-normalizer, idna, urllib3\n",
      "Required-by: aext-assistant-server, anaconda-catalogs, anaconda-client, anaconda-cloud-auth, anaconda-project, conda, conda-build, conda-repo-cli, conda_package_streaming, cookiecutter, datashader, jupyterlab_server, panel, requests-file, requests-toolbelt, Sphinx, streamlit, tldextract\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "97214439-be65-4b06-9077-dc5451b2876c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: beautifulsoup4\n",
      "Version: 4.12.3\n",
      "Summary: Screen-scraping library\n",
      "Home-page: https://www.crummy.com/software/BeautifulSoup/bs4/\n",
      "Author: \n",
      "Author-email: Leonard Richardson <leonardr@segfault.org>\n",
      "License: MIT License\n",
      "Location: C:\\Users\\hun\\anaconda3\\Lib\\site-packages\n",
      "Requires: soupsieve\n",
      "Required-by: conda-build, nbconvert\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6571e16d-2295-44cc-aef7-32d5f8139485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reqeusts, bs4 import\n",
    "import requests\n",
    "import bs4\n",
    "# BeautifulSoup í´ë˜ìŠ¤ import\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "007d5514-a9e7-4b99-a16a-62d9babd99b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests ë²„ì „ 2.32.3\n",
      "beautifulsoup4 ë²„ì „ 4.12.3\n"
     ]
    }
   ],
   "source": [
    "# requests, bs4 ë²„ì „ í™•ì¸í•˜ê¸°\n",
    "print(f'requests ë²„ì „ {requests.__version__}')\n",
    "print(f'beautifulsoup4 ë²„ì „ {bs4.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fae2baab-c168-4154-a495-08659ad7c4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìš”ì²­ URL: https://www.chosun.com\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# IT/ê³¼í•™ ë‰´ìŠ¤\n",
    "req_param = {\n",
    "    'sid': 105\n",
    "}\n",
    "\n",
    "# Naver ë‰´ìŠ¤ IT/ê³¼í•™ ì„¹ì…˜ URL\n",
    "url = 'https://news.naver.com/section/{sid}'.format(**req_param)\n",
    "\n",
    "print(\"ìš”ì²­ URL:\", url)\n",
    "\n",
    "# ìš”ì²­ í—¤ë” ì„¤ì • : ë¸Œë¼ìš°ì € ì •ë³´ í‰ë‚´ë‚´ê¸°\n",
    "req_header = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# GET ìš”ì²­ ë³´ë‚´ê¸°\n",
    "response = requests.get(url, headers=req_header)\n",
    "\n",
    "# ì‘ë‹µ í™•ì¸\n",
    "if response.status_code == 200:\n",
    "    # ì‘ë‹µì—ì„œ HTML ì¶”ì¶œ\n",
    "    html = response.text\n",
    "\n",
    "    # BeautifulSoup ê°ì²´ ìƒì„±\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # ë‰´ìŠ¤ ë§í¬ ì°¾ê¸° (ëª¨ë°”ì¼ ë‰´ìŠ¤ article ë§í¬ í¬í•¨ëœ <a> íƒœê·¸ë“¤)\n",
    "    links = soup.select(\"div.sa_text a[href*='mnews/article']\")\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    for link in links:\n",
    "        print(link.text.strip())\n",
    "        print(\"ê¸°ì‚¬ ë§í¬:\", link['href'])\n",
    "        print('-' * 40)\n",
    "else:\n",
    "    print(\"ìš”ì²­ ì‹¤íŒ¨, ìƒíƒœì½”ë“œ:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "75043aca-e1ae-4a36-b5e0-7034655cbffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¢ [ìƒí™œ/ë¬¸í™”] ë‰´ìŠ¤ ëª©ë¡\n",
      "----------------------------------------\n",
      "ì œ21ëŒ€ ëŒ€í†µë ¹ ì„ ê±°ì¼ '6ì›” 3ì¼ í™”ìš”ì¼' í™•ì •â€¦ì„ì‹œê³µíœ´ì¼ ì§€ì •\n",
      "ë§í¬: https://n.news.naver.com/mnews/article/055/0001247361\n",
      "------------------------------\n",
      "\n",
      "ë§í¬: https://n.news.naver.com/mnews/article/comment/055/0001247361\n",
      "------------------------------\n",
      "êµ­ë¯¼ì˜í˜ \"ì´ì¬ëª… ê°œí—Œ ê±°ë¶€, ì‹œëŒ€ì  ìš”êµ¬ ì™¸ë©´í•˜ëŠ” ê²ƒ\"\n",
      "ë§í¬: https://n.news.naver.com/mnews/article/055/0001247151\n",
      "------------------------------\n",
      "\n",
      "ë§í¬: https://n.news.naver.com/mnews/article/comment/055/0001247151\n",
      "------------------------------\n",
      "í™ì¤€í‘œ \"íƒ„í•µë˜ë©´ ì°¨ê¸° ëŒ€ì„  í¬ê¸°í•´ì•¼Â·Â·Â·ë‹¹ì´ ì—†ì–´ì§€ëŠ” ê±°ì§€\" 2024ë…„ 9ì›” 'TVí™ì¹´ì½œë¼' ë‹¤ì‹œ ë´¤ë”ë‹ˆ\n",
      "ë§í¬: https://n.news.naver.com/mnews/article/657/0000037003\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "section_dict = {\n",
    "    100: 'ì •ì¹˜',\n",
    "    101: 'ê²½ì œ',\n",
    "    102: 'ì‚¬íšŒ',\n",
    "    103: 'ìƒí™œ/ë¬¸í™”',\n",
    "    104: 'ì„¸ê³„',\n",
    "    105: 'IT/ê³¼í•™'\n",
    "}\n",
    "\n",
    "def print_news(sid, section):  # ì˜ˆ: print_news(103, 'ìƒí™œ/ë¬¸í™”')\n",
    "    print(f\"ğŸ“¢ [{section}] ë‰´ìŠ¤ ëª©ë¡\")\n",
    "    print('-' * 40)\n",
    "\n",
    "    url = f'https://news.naver.com/section/{sid}'\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        links = soup.select(\"div.sa_text a[href*='mnews/article']\")\n",
    "\n",
    "        for link in links[:5]:  # ìƒìœ„ 5ê°œë§Œ ì¶œë ¥\n",
    "            print(link.text.strip())\n",
    "            print(\"ë§í¬:\", link['href'])\n",
    "            print('-' * 30)\n",
    "    else:\n",
    "        print(\"âŒ ìš”ì²­ ì‹¤íŒ¨:\", response.status_code)\n",
    "\n",
    "# í•¨ìˆ˜ í˜¸ì¶œ\n",
    "print_news(100, section_dict[103])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c85517-6b34-4f8a-abd2-616a1eebc273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
